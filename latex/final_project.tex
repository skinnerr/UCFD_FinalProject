\documentclass[11pt]{article}

\input{./preamble.tex}

%%
%% DOCUMENT START
%%

\begin{document}
\fancypagestyle{allpages}
{
	\fancyhf[LH]{\rightmark}
	\fancyhf[CH]{}
	\fancyhf[RH]{\thepage\hspace*{1ex}/\hspace*{1ex}\pageref{lastpage}}
	\fancyhf[LF]{}
	\fancyhf[CF]{}
	\fancyhf[RF]{}
}

\fancypagestyle{firstpage}
{
	\fancyhf[LH]{\Large Final Project \\ \large ASEN 5519: Unstructured CFD}
	\fancyhf[CH]{}
	\fancyhf[RH]{\large Ryan Skinner \\ \large Due 2016/??/??}
	\fancyhf[LF]{}
	\fancyhf[CF]{}
	\fancyhf[RF]{}
}

\pagestyle{allpages}
\thispagestyle{firstpage}
\renewcommand{\sectionmark}[1]{ \markright{#1}{} }

\vspace*{0in}
\begin{center}
\LARGE Improving Boundary Condition Stability in PHASTA
\end{center}
\vspace*{0.3in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Initial Outline of PHASTA}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

PHASTA begins execution at |main|, located in |phSolver/[in]compressible|, depending on which branch is desired. This function initializes MPI, and then calls |phasta|, located in |/phSolver/common|. Here, inputs are read and computed in |input|, and then the solver is run by calling |proces|, a Fortran routine. Within |proces|, |gendat| generates geometry and BC data.

Routines followed by an asterisk (\ra) are outlined in further detail separately.

{\huge \color{red!75!black} INCOMPRESSIBLE ONLY}, and we ignore cardiovascular impedance and RCR boundary stuff.

\begin{outline}[deep]
\1 |main|
	\2 initialize MPI
	\2 |phasta|
		\3 initialize PETSc
		\3 |input_fform| --- read ASCII data from |input.config| and |solver.inp|
		\3 |input|\ra --- populate data structures with problem set-up and solver parameters
		\3 |proces|\ra --- generate problem data and calls the solution driver
		\3 finalize PETSc
	\2 finalize MPI
\end{outline}

Inputs:
\begin{outline}[deep]
\1 |input| --- populate data structures with problem set-up and solver parameters
	\2 |readnblk| --- read and blocks data
		\3 read |numstart.dat| and finds appropriate |restart.dat| files
		\3 read geometry from Posix or SyncIO files using |phio_readheader|
		\3 calculate maximum number of boundary element nodes
		\3 initialize constants like |ndof|, |ndofBC|, |ndiBCB|, and |ndBCB|
		\3 |genblk| --- read and block connectivity
		\3 read BC mapping array into |nBC|
		\3 read temporary boundary condition code into |iBCtmp|
		\3 read BC data into |BCinp|
		\3 read periodic BC data into |iperread|
		\3 |genbkb| --- generate boundary element blocks and traces for gather/scatter operations
		\3 read restart data for solution |qold|, displacement |uold|, and accelerations |acold|
	\2 assert valid input constants (e.g. |icoord|, |navier|, |iexec|) defined in |common.h|
	\2 |genint| --- generate integration information: number of quadrature points on the interior |nint| and boundary |nintb|, their weights |Qwt| and |Qwtb|, and locations |Qpt| and |Qptb|
	\2 estimate number of global nonzeros |nnz| based on basis function order |ipord|
	\2 compute fluid thermodynamic properties
\end{outline}

Process:
\begin{outline}[deep]
\1 |proces| --- generate problem data and call the solution driver
	\2 |gendat| --- generate geometry and BC data
		\3 |genshp| --- generate interior element shape functions and derivatives
			\4 loop through element topologies, getting their coordinate system and element type, and then generate the parent element shape functions and their derivatives by calling either |shpTet| (tets), |shphex| (hexes), |shp6w| (wedges), or |shppyr| (pyramids)
			\4 these are all C routines, and some are in |phasta/shapeFunction/|, whereas others are in |phasta/phSolver|
			\4 return |shp(a,i,j,p)| and |shgl(a,i,p)|, which are indexed by topology index |a|, spatial dimension(s) |i| and |j|, and the integration point index $|p| = 1, ..., |nint|$
		\3 |geniBC| --- generate boundary condition codes
			\4 set |iBC = iBCtmp| if this partition has boundary nodes; see code for |BCinp| description
		\3 |genBC| --- generate the essential boundary conditions
			\4 set |BCtmp = BCinp| if this partition has boundary nodes; |BCtmp(nshg,6+5*I3nsd)| has a second index of $\rho$, $T$, $p$, velocities, scalars (?)
			\4 |genwnm| --- calculate wall normals and modify |BCtmp| with the appropriate constraints
			\4 |genotwn| --- determine first ``off-the-wall-node'' for each node, store result in |otwn(nshg)|
			\4 |genBC1| --- account for arbitrarily-oriented velocity constraints $u_r$, $u_s$, and $u_t$, finally storing the simplified boundary condition constraint result in |BC|; note that second index of |BC| holds $\rho$, $T$, $p$, $u_1$, $u_2$, $u_3$, and scalars
		%\3 work with Dirichlet-to-Neumann BCs (?)
		\3 |genshpb| --- generate boundary element shape functions and derivatives (like |genshp|), storing results in |shpb| and |shglb|
		\3 LES: call |setfilt|, |filtprep|, and depending on |iLES|' value, |setave| and |aveprep|
		\3 |genini| --- generate initial values of solution variables
			\4 |restar| --- sort initial values into |y| (called |q| inside |restar|) and |ac| from |qold| and |acold|, respectively, that were read in |readnblk|
			\4 |itrBC|\ra and |itrBCSclr|\ra --- satisfy BCs
	\2 |setper| and |perprep| --- store inverse of sum of one and number of slaves in |rcount|
	\2 LES: |keeplhsG| and |setrls|
	\2 |initStats| --- allocate arrays to store flow statistics
	\2 RANS: |initTurb|
	%\2 cardiovascular-specific routine |initSponge|
	%\2 adjust BCs to interpolate from file |inlet.dat|, if it exists
	%\2 set up eddy-viscosity ramp specific to NGC/Duct case
	\2 |itrdrv|\ra --- iterate the discrete solution using the predictor multi-corrector algorithm
\end{outline}

Numerical solution of the time-integrated unsteady Navier-Stokes equations occurs within |itrdrv|. Working arrays are listed in Table \ref{tbl:symbols}.
\begin{outline}[deep]
\1 |itrdrv|
	\2 |initTimeSeries| --- initialize time series collection to |varts.*.dat| files using |xyzts.dat| input
	\2 initialize |istep| and |ifuncs(:)| to zero
	\2 set |yold = y| and |acold = ac|, that is, populate $\oset{n}{\ul{Y}}$ and $\oset{n}{\ul{Y}_{,t}}$ with their converged solutions from the previous time step, which came from a restart file
	\2 |initEQS| --- create the |rowp| and |colm| maps to facilitate sparse storage of the tangent matrix
		\3 determine how many scalar equations need solution, |nsclrsol| (\# scalars + 1 if temperature)
		\3 determine whether we are solving the flow
		\3 |genadj| --- pre-process the adjacency list
			\4 |do iblk = 1, nelblk| --- loop over blocks (groups of elements with the same topology)
				\5 |Asadj| --- generate adjacency data structures |row_fill_list| and |adjcnt|
					\6 declare |row_fill_list| to have dimension |(nshg, 15*nnz)|, where |15*nnz| is a high estimate of the maximum number of adjacent nodes
					\6 |row_fill_list(A,:)| holds global nodes that share local support with global node |A|
					\6 |adjcnt(A)| holds the number of nodes adjacent to |A|, that is, how many entries |row_fill_list(A,:)| was populated with on purpose
					\6 \emph{note}: some operations here are $\bigo(n^2)$, but $n$ is relatively small on each processor, and this process only needs to be done once for a given mesh connectivity
			\4 build the |colm| array (which is trivial to do at this point)
			\4 sort |rowp|, because we binary search it when computing the sparse $\uul{A}\:\ul{p}$-product, and also compute the number of non-zero blocks |icnt| on this partition
		\3 set |nnz_tot = icnt|
		\3 depending on |nsolflow| and |nsclrsol| (whether this is a flow or scalar solve), initialize certain constants, such as |equType|, |nDofs|, |nPermDims|, |nTmpDims|, and allocate certain arrays, such as |apermS| and |atempS|
	\2 initialize |lstep0 = lstep + 1| to hold the first time step solved by the current run
	\2 |do itsq = 1, ntseq| --- loop over time sequences; as far as I can tell |ntseq = 1| is the default in |input.config|, and time sequences are not often used
		\3 set |itseq = itsq|
		\3 set iteration-specific variables |nstp = nstep|, |nitr = niter|, |LCtime = loctim|, and |dtol(:) = deltol(:)|, where all of the longer-named variables are indexed by |itseq|
		\3 |itrSetup| --- set up time integration parameters
			\4 calculate $\alpha_m$, $\alpha_f$, and $\gamma$ as functions of $\rho_\infty$ (|almi|, |alfi|, and |gami| as functions of |rhoinf|)
			%\4 set Jacobian type (appears to be for a fringe case only?)
			%\4 mess with |ipred| and |y| for the same-delta predictor if we're on the first sequence
			\4 set inverse of global time step |Dtgl| and CFL data |CFLfl|
		\3 calculate number of flow solves per time step, store in |nitr| (IC), |niter| (C)
		\3 initialize |istop = 0|; flag can be set to stop the solver based on statistics of the residual
		\3 |do istp = 1, nstp| --- main loop over time steps
			\4 LES: |lesmodels|
			\4 |asbwmod| --- set traction BCs if turbulence wall model is set (|itwmod|)
			\4 |itrPredict|\ra --- predict primitive variables at time $n+1$
			\4 |itrBC|\ra --- satisfy BCs on primitive variables; return a modified |y|
			\4 |itrBCSclr| --- satisfy BCs on scalar |isclr|; return a modified |y|
			\4 |do istepc = 1, seqsize| --- loop over individual solves of flow and scalar
				\5 |icode = stepseq(istepc)| --- get sequence code
				\5 |if| this is a flow solve
					\6 |SolFlow|\ra --- perform a flow solve
				\5 |else if| this is a scalar solve
					\6 |SolSclr| --- perform a scalar solve
				\5 |else| this is an update
					\6 |itrCorrect|\ra and |itrBC|\ra --- update flow if desired
					\6 |itrCorrectSclr| and |itrBCSclr| --- update scalar if desired
			\4 |stsGetStats| --- obtain time averaged statistics
			\4 find solution at end of time step and move it to old solution variables
			\4 increment |istep| and |lstep|
			\4 |Bflux| --- compute the consistent boundary flux if desired
		\3 deallocate variables and close files
	\2 deallocate variables and close files
\end{outline}

Iteration routines...

\begin{outline}[deep]
\1 |itrPredict| --- predict solution variables at time $n+1$
	\2 |if (ipred .eq. 1)| --- we are using same-velocity prediction, as discussed in class
		\3 set $\oset{n+1}{\ul{Y}}^{(i)} = \oset{n}{\ul{Y}}$ with |y = yold|
		\3 set $\oset{n+1}{\ul{Y}}^{(i)}_{,t} = (1-1/\gamma) \oset{n}{\ul{Y}}_{,t}$ with |ac = acold * (gami-one)/gami|
	\2 other prediction methods (zero-acceleration, same-acceleration, and same-delta) are also supported with different values of |ipred|
\end{outline}

Boundary conditions are set with the |iBC| and |BC| arrays. The bits of |iBC|, in increasing order, indicate whether the following BCs are set: $\rho$, $T$, $p$, $u_1$, $u_2$, $u_3$, scalars 1--4, periodicity, scaled plane extraction (SPEBC), axisymmetry, and deformable wall (for cardiovascular cases). This means for each global node, |iBC| has at least 14 bits. Note that |ibits(i,a,l)| extracts bits |a+1| through |a+l| of the integer |i|, and returns the base-10 integer. This routine is used to help identify and process boundary condition flags held in |iBC|. For example, if |ibits(iBC,3,3) .eq. 1| then $u_1$ is the only velocity component specified essential BC.
\begin{outline}[deep]
\1 |itrBC| --- satisfy BCs on the primitive variables
	\2 impose limits on flow variables in |y|, using the |ylimit| data structure of dimension |(3, nflow)|, whose first index contains the limit flag, lower limit, and upper limit for each flow variable
	\2 velocity
	\2 pressure
	\2 local periodic
	\2 global periodic
\end{outline}

Once boundary conditions have been satisfied, |SolFlow| is called to perform a flow solve:
\begin{outline}[deep]
\1 |SolFlow| --- perform a flow solve; output |res| preconditioned residual, 
	\2 |itrYAlpha| --- compute $\oset{n+\alpha_f}{\ul{Y}}^{(i)}$ and $\oset{n+\alpha_m}{\ul{Y}}^{(i)}_{,t}$, store respectively in |yAlpha| and |acAlpha|
	\2 |ElmGMR| --- compute tangent matrix, residual vector, and preconditioning matrix for GMRES
\end{outline}

Going through lectures 26 and 27.

First in the compressible code.
Data structures are used in |solgmr| -> |elmgmrs| (sparse). Section on diffusive flux reconstruction, set up some arrays for interior elements. call |asigmr|, took care of volume integrals. now come to boundary elements, which is where integral over gamma takes place. block boundary elements as a separate list of elements with separate connectivity. as |asbmfg| is called, |mienb| holds boundary elements. computing normal gradients requires nodes off of the boundary. solution goes into |asbmfg| (no time derivatives are input, unlike |asigmr|), out comes a modified solution. in |asibmfg|: working with a block of elements; solution and coordinates are localized, local residual is zeroed, call |e3b|, assemble local residual. in |e3b|: loop over quadrature points (|ngaussb|), |getshpb| to get boundary shape functions, |e3bvar| called with surface normals, need |Fv{2,3,4}| to evaluate the floating flux, let |e3bvar| compute |Fv| values and fluxes, then test if we should use computed value or value from prescribed boundary condition. in |e3bvar|: interpolate nodal values to quadrature points, call |getthm| to compute thermodynamic state, compute element metrics for mapping physical space to get |wdetj|, compute |rou|,|p| and |tau*n|,|heat| (normal flux, pressure, traction vector, heat flux) that is, |rou| takes $h^m(\xi_l)$, |p| takes $h^p(\xi_l)$, |tau*n| takes $h^v_*(\xi_l)$, etc. what's passed out is these things and the raw variables, their gradients, and the derived thermodynamic state. Back to |e3b|, do convective pressure, n-s, heat terms. after return from |e3bvar|, if no natural bc flag is set, we overwrite |rou|,|p| with floating values. compute euler stuff; then compute viscous stuff. get floating flux |tau*n|, overwrite where bits are not set. be careful what's passed out and in. also compute aerodynamic forces and heat flux in |e3b|, since we're doing surface integrals anyway.

incompressible is different, slightly. don't interpolate temperature at the outset; compute normal via cross-product; compute deformation gradient, local and global variable gradients; |unm| has the floating value of $\ul{u} \cdot \ul{n}$. eventually compute |tau*n|, which has the total stress floating value. skip over a bunch of deforming-wall stuff. iBCB did not come in to e3bvar; only floating flux stuff is computed in |e3bvar| for incompressible. all nodal interpolation is now done in |e3b|:

for Dirichlet bcs, |iBC| was a bitmap to boundary conditions |BC|

for natural bcs, |ibcb|(1:nel$_\text{in block (npro)}$,...) is a bitmap to boundary conditions |BCB|(:,...), where ... takes normal flux, pressure, traction vector, and heat flux take values 1--4.

going through more code... (2016-03-30)

this stuff is used in |irdrv| when it calls |solgmrs|, calls |elmgmrs| to populate lshk with current iteration's tangent values (same for |res|). allows us to start |gmres|; factorize matrix; precondition rhs with |i3lu|; |spsi3pre| sparse matrix preconditioning of |lhsk|; copy preconditioned residual into |uBrg|, which is a collection or Krylov vectors; calculate it's norm, make orthonormal; outer gmres loop |do 2000| can be skipped, which is the gmres restart; actual start of GMRES discussed in class is |uBrg| statement just before |do 1000|; |sumgat| does off-processor (communication).


\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
Symbol & Dimension & Description \\
\midrule
|nshg|   &  & \# global shape functions (|nshg| = |nnp| if piecewise linear) \\
|nnp|    &  & \# global nodal points \\
|npro|   &  & \# elements in a block of same-topology elements, indexed by $e$ \\
|nshl|   &  & \# nodes per element, indexed by $a$ \\
|ndof|   &  & \# degrees of freedom, including scalars for turbulence models \\
|nflow|  &  & \# flow variables (4 incompressible, 5 compressible) \\
|ntseq|  &  & \# time sequences, which seems seldom used and defaults to 1 \\
|nstep|  &  & \# time steps requested per sequence \\
|nelblk| &  & \# blocks \\
|ipord|  &  & order of basis functions \\
|lstep|  &  & current time step \\
|lstep0| &  & first time step solved by current run, initialized to |lstep+1| \\
|istep|  &  & step number relative to start of run \\
|iter|   &  & iteration number \\
|niter|  & |(MAXTS)|    & \# multi-corrector iterations per time step \\
|loctim| & |(MAXTS)|    & local time stepping flag (?) \\
|deltol| & |(MAXTS, 2)| & velocity and pressure delta ratios \\
|impl|   & |(MAXTS)|    & heat, flow, and scalar solver flags (1's, 10's and 100's places) \\
|iturb|  &  & indicates which turbulence model to use \\
|ifunc|  &  & function evaluation counter, |niter*(lstep-lstep0)+iter| \\
|ifuncs| & |(6)|						& function evaluation counter (?) \\
|y|      & |(nshg, ndof)|            & $\oset{n+\alpha_f}{\ul{Y}}_{A}^{(i)}$ (meaning changes throughout) \\
|ac|     & |(nshg, ndof)|            & $\oset{n+\alpha_m}{\ul{Y}}_{A,t}^{(i)}$ (meaning changes throughout) \\
|yold|   & |(nshg, ndof)|            & $\oset{n}{\ul{Y}}_{A}^{(i)}$ (meaning changes throughout) \\
|acold|  & |(nshg, ndof)|            & $\oset{n}{\ul{Y}}_{A,t}^{(i)}$ (meaning changes throughout) \\
|x|      & |(nshg, nsd)|             & node coordinates \\
|iBC|    & |(nshg)|                  & BC codes \\
|BC|     & |(nshg, ndofBC)|          & BC constraint parameters \\
|iper|   & |(nshg)|				    & periodicity table \\
|mien|   & |(nelblk)|			    & pointer to IEN array (interior): has dimension |(nshg, 15*nnz)| \\
|mienb|  & |(nelblk)|			    & pointer to IEN array (boundary): has dimension |(nshg, 15*nnz)| \\
|shp|    & |(nshape, ngauss)|        & element shape functions at Gauss points (interior) \\
|shb|    & |(nshapeb, ngaussb)|      & element shape functions at Gauss points (boundary) \\
|shgl|   & |(nsd, nshape, ngauss)|   & local shape function gradients at Gauss points (interior) \\
|shglb|  & |(nsd, nshapeb, nguassb)| & local shape function gradients at Gauss points (boundary) \\
\bottomrule
\end{tabular}
\label{tbl:symbols}
\end{center}

\section{General Notes}
\begin{outline}[deep]
\1 In PHASTA, a block contains elements of the same topology.
\end{outline}

\section{Life's Persistent PHASTA Questions}
\begin{outline}[deep]
	\1 Is |qold|, allocated in |readnblk.f| ever deallocated? Can't find it.
	\1 Why do most of the time step parameters have dimension |MAXTS|?
		\2 It also seems that some parameters are indexed by |itseq|, but don't change from step to step.
	\1 When is it the case that $|ndof| \ne |nflow|$? For example during its limit-imposing stage, |itrbc| loops over |nflow| when indexing |y|'s dimension of size |ndof|.
	\1 Often the value of |datmat(1,2,1)| is assigned to a variable like |rmu|; where it it calculated? Kinematic viscosity? See |getdiff|.
	\1 In |genBC1|, |BC(:,1)| gets assigned both density and pressure, so what goes in |BC(:,6)|???
\end{outline}

%%
%% DOCUMENT END
%%
\label{lastpage}
\end{document}






