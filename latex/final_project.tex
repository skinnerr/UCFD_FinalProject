\documentclass[11pt]{article}

\input{./preamble.tex}

%%
%% DOCUMENT START
%%

\begin{document}
\fancypagestyle{allpages}
{
	\fancyhf[LH]{\rightmark}
	\fancyhf[CH]{}
	\fancyhf[RH]{\thepage\hspace*{1ex}/\hspace*{1ex}\pageref{lastpage}}
	\fancyhf[LF]{}
	\fancyhf[CF]{}
	\fancyhf[RF]{}
}

\fancypagestyle{firstpage}
{
	\fancyhf[LH]{\Large Final Project Proposal and Outline \\ \large ASEN 5519: Unstructured CFD}
	\fancyhf[CH]{}
	\fancyhf[RH]{\large Ryan Skinner \\ \large Due 2016/04/01}
	\fancyhf[LF]{}
	\fancyhf[CF]{}
	\fancyhf[RF]{}
}

\pagestyle{allpages}
\thispagestyle{firstpage}
\renewcommand{\sectionmark}[1]{ \markright{#1}{} }

\vspace*{0in}
\begin{center}
\LARGE Improving Compressible BC Robustness in PHASTA
\end{center}
\vspace*{0.3in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposal}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For the final project, I propose a detailed investigation and improvement of boundary condition implementation in the compressible version of PHASTA. Currently, the incompressible version's non-linear convergence is much more robust than that of the compressible version; it often takes considerable manual effort to push a compressible case through its initial transient. By studying the incompressible version's implementation of BCs, I will identify aspects of the compressible code for improvement. The final deliverable will be a detailed algorithmic outline of both codes' BC implementation, a discussion of improvements selected for study, and benchmarks of the degree to which they affect non-linear convergence of a familiar compressible case: that of the aggressive subsonic diffuser.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Initial Outline of PHASTA: Incompressible}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Though the final deliverable will include outlines of the BC implementation in both compressible and incompressible versions of PHASTA, the initial outline will be presented here using the latter version due to its robustness. In the following outline, routines followed by an asterisk (\ra) are expanded and described in their own separate block. Important integers and arrays are listed in Table \ref{tbl:symbols}. Furthermore, we ignore cardiovascular impedance and RCR boundary condition statements.

PHASTA begins execution at |main|, located in |phSolver/[in]compressible|, depending on which branch is desired. This function initializes MPI, and then calls |phasta|, located in |/phSolver/common|. Here, inputs are read and computed in |input|, and then the solver is run by calling |proces|.

\begin{outline}[deep]
\1 |main|
	\2 initialize MPI
	\2 |phasta|
		\3 initialize PETSc
		\3 |input_fform| --- read ASCII data from |input.config| and |solver.inp|
		\3 |input|\ra --- populate data structures with problem set-up and solver parameters
		\3 |proces|\ra --- generate problem data and calls the solution driver
		\3 finalize PETSc
	\2 finalize MPI
\end{outline}

Most file input occurs in |input|, which populates data structures with problem and solver parameters.
\begin{outline}[deep]
\1 |input|
	\2 |readnblk| --- read and block data
		\3 read |numstart.dat| and finds appropriate |restart.dat| files
		\3 read geometry from Posix or SyncIO files using |phio_readheader|
		\3 calculate maximum number of boundary element nodes
		\3 initialize constants like |ndof|, |ndofBC|, |ndiBCB|, and |ndBCB|
		\3 |ctypes| --- initialize variables for parallel processing
		\3 |genblk| --- read and block connectivity for interior elements; there are two other versions of this function, |genblkPosix| and |genblkSyncIO|, which just address idiosyncrasies of the file formats; all call |gensav|
			\4 |gensav| --- save element block data to and return an |ien| array, mapping element and local node numbers to global node number, and a material type flag |mater|
		\3 read BC mapping array into |nBC|
		\3 read temporary boundary condition code into |iBCtmp|
		\3 read BC data into |BCinp|
		\3 read periodic BC data into |iperread|
		\3 |genbkb| --- generate boundary element blocks and traces for gather/scatter operations; there are two other versions of this function, |genbkbPosix| and |genbkbSyncIO|, which just address idiosyncrasies of the file formats; all call |gensvb|
			\4 |gensvb| --- save boundary element block data to and return boundary nodal connectivity |ienb|, boundary condition codes |iBCB|, boundary condition values |BCB|, and material type flag |materb|
		\3 read restart data for solution |qold|, displacement |uold|, and accelerations |acold|
	\2 assert valid input constants (e.g. |icoord|, |navier|, |iexec|) defined in |common.h|
	\2 |genint| --- generate integration information: number of quadrature points on the interior |nint| and boundary |nintb|, their weights |Qwt| and |Qwtb|, and locations |Qpt| and |Qptb|; the following routines are called to populate these variables depending on type of element and whether it is on the boundary
		\3 |symtet| --- interior tetrahedra
		\3 |symtri| --- boundary tetrahedra, boundary wedges (if boundary face is a triangle)
		\3 |symhex| --- interior hexahedra
		\3 |symquad| --- boundary hexahedra, boundary pyramids (if boundary face is a quadrilateral)
		\3 |sympyr|--- interior pyramids
		\3 |symtripyr| --- boundary pyramids (if boundary face is a triangle)
		\3 |symwdg| --- interior wedges
		\3 |symquadw| --- boundary wedges (if boundary face is a quadrilateral)
	\2 estimate number of global nonzeros |nnz| based on basis function order |ipord|
	\2 compute fluid thermodynamic properties, such as specific heats and the gas constant
\end{outline}

The next overarching routine, |proces|, generates problem data and calls the solution driver.
\begin{outline}[deep]
\1 |proces|
	\2 |gendat| --- generate geometry and BC data
		\3 |xyzbound| --- compute length scales (domain size) of the problem by looking at minima and maxima of the |x| array
		\3 |genshp| --- generate interior element shape functions and shape function derivatives
			\4 loop through element topologies, getting their coordinate system and element type, and then generate the parent element shape functions and their derivatives by calling either |shpTet| (tets), |shphex| (hexes), |shp6w| (wedges), or |shppyr| (pyramids)
			\4 these are all Fortran wrappers (located in |phasta/common/*.c|) for the C routines called |TetShapeAndDrv| (in |shapeFunction/src/uniformP.c|), |HexShapeAndDrv|, |WedgeShapeAndDrv|, and |PyrShapeAndDrv| (these three in |phasta/common/newshape.cc|) respectively
			\4 return |shp(a,i,j,p)| and |shgl(a,i,p)|, which are indexed by topology index |a|, spatial dimension(s) |i| and |j|, and the integration point index $|p| = 1, ..., |nint|$
		\3 |geniBC| --- generate boundary condition codes, stored as a bitmap for each global node number (bitmap described just before description of |iBC| routine in this document)
			\4 set |iBC(:) = iBCtmp(nBC(:))| if this partition has boundary nodes; |nBC| is used to map from the |iBCtmp| data read in |readnblk| to |iBC|, which is indexed by the full global node number
		\3 |genBC| --- generate the essential boundary conditions
			\4 set |BCtmp = BCinp| if this partition has boundary nodes; |BCtmp(nshg,6+5*I3nsd)| has a second index of $\rho$, $T$, $p$, velocities, scalars (?)
			\4 |genwnm| --- calculate wall normals and modify |BCtmp| with the appropriate constraints
			\4 |genotwn| --- determine first ``off-the-wall-node'' for each node, store result in |otwn(nshg)|
			\4 |genBC1| --- account for arbitrarily-oriented velocity constraints $u_r$, $u_s$, and $u_t$, finally storing the simplified boundary condition constraint result in |BC|; note that second index of |BC| holds $\rho$, $T$, $p$, $u_1$, $u_2$, $u_3$, and scalars
		\3 |genshpb| --- generate boundary element shape functions and derivatives, storing results in |shpb| and |shglb|; this routine is analogous to |genshp|
		\3 LES: call |setfilt|, |filtprep|, and depending on |iLES|' value, |setave| and |aveprep|
		\3 |genini| --- generate initial values of solution variables
			\4 |restar| --- sort initial values into |y| (called |q| inside |restar|) and |ac| from |qold| and |acold|, respectively, that were read in |readnblk|
			\4 |itrBC|\ra and |itrBCSclr|\ra --- satisfy BCs, outlined later in this document
	\2 |setper| and |perprep| --- allocate and store inverse of sum of one and number of slaves in |rcount|, in preparation for dealing with periodic boundaries
	\2 LES: |keeplhsG| and |setrls|
	\2 |initStats| --- allocate arrays to store flow statistics
	\2 RANS: |initTurb|
	\2 |itrdrv|\ra --- iterate the discrete solution using the predictor multi-corrector algorithm
\end{outline}

Numerical solution of the time-integrated unsteady Navier-Stokes equations occurs within |itrdrv|.
\begin{outline}[deep]
\1 |itrdrv|
	\2 |initTimeSeries| --- initialize time series collection to |varts.*.dat| files using |xyzts.dat| input
	\2 initialize |istep| and |ifuncs(:)| to zero
	\2 set |yold = y| and |acold = ac|, that is, populate $\oset{n}{\ul{Y}}$ and $\oset{n}{\ul{Y}_{,t}}$ with their converged solutions from the previous time step, which came from a restart file
	\2 |initEQS| --- create the |rowp| and |colm| maps to facilitate sparse storage of the tangent matrix
		\3 determine how many scalar equations need solution, |nsclrsol| (\# scalars + 1 if temperature)
		\3 determine whether we are solving the flow
		\3 |genadj| --- pre-process the adjacency list
			\4 |do iblk = 1, nelblk| --- loop over element blocks (groups of elements with the same topology)
				\5 |Asadj| --- generate adjacency data structures |row_fill_list| and |adjcnt|
					\6 declare |row_fill_list| to have dimension |(nshg, 15*nnz)|, where |15*nnz| is a high estimate of the maximum number of adjacent nodes
					\6 |row_fill_list(A,:)| holds global nodes that share local support with global node |A|
					\6 |adjcnt(A)| holds the number of nodes adjacent to |A|, that is, how many entries |row_fill_list(A,:)| was populated with on purpose
					\6 \emph{note}: some operations here are $\bigo(n^2)$, but $n$ is relatively small on each processor, and this process only needs to be done once for a given mesh connectivity
			\4 build the |colm| array (which is trivial to do at this point)
			\4 sort |rowp|, because we binary search it when computing the sparse $\uul{A}\:\ul{p}$-product, and also compute the number of non-zero element blocks |icnt| on this partition
		\3 set |nnz_tot = icnt|
		\3 depending on |nsolflow| and |nsclrsol| (whether this is a flow or scalar solve), initialize certain constants, such as |equType|, |nDofs|, |nPermDims|, |nTmpDims|, and allocate certain arrays, such as |apermS| and |atempS|
	\2 |genlmass| --- generates lumped mass matrix |gmass| if we are using a lumped mass fraction on either the LHS or RHS
		\3 |AsImass| assembles the interior lumped mass matrix within a loop over element blocks
			\4 |localx| --- gather node coordinates to local frame
			\4 |do intp = 1, ngauss| --- loop over Gauss points
				\5 |getshp| --- returns the shape functions evaluated at this point, |shape| and |shdrv|
				\5 |e3metric| --- compute the deformation gradient ($dx_i/d\xi_j$ or |dxdxi(npro,i,j)|) and its inverse (|dxidx|), as well as the quadrature-weighted Jacobian determinant |WdetJ| and the global shape function gradient |shg|
				\5 add contribution of this Gauss point to the local mass matrix
			\4 compute the trace and scale the diagonal, operating on local mass matrices
			\4 |local| --- assemble the global residual, |gmass|
	\2 initialize |lstep0 = lstep + 1| to hold the first time step solved by the current run
	\2 |do itsq = 1, ntseq| --- loop over time sequences; as far as I can tell |ntseq = 1| is the default in |input.config|, and time sequences are not often used
		\3 set |itseq = itsq|
		\3 set iteration-specific variables |nstp = nstep|, |nitr = niter|, |LCtime = loctim|, and |dtol(:) = deltol(:)|, where all of the longer-named variables are indexed by |itseq|
		\3 |itrSetup| --- set up time integration parameters
			\4 calculate $\alpha_m$, $\alpha_f$, and $\gamma$ as functions of $\rho_\infty$ (|almi|, |alfi|, and |gami| as functions of |rhoinf|)
			\4 set inverse of global time step |Dtgl| and CFL data |CFLfl|
		\3 calculate number of flow solves per time step, store in |nitr| (IC), |niter| (C)
		\3 initialize |istop = 0|; flag can be set to stop the solver based on statistics of the residual
		\3 |do istp = 1, nstp| --- main loop over time steps
			\4 LES: |lesmodels|
			\4 |asbwmod| --- set traction BCs if turbulence wall model is set (|itwmod|)
			\4 |itrPredict|\ra --- predict primitive variables at time $n+1$
			\4 |itrBC|\ra --- satisfy BCs on primitive variables; return a modified |y|
			\4 |itrBCSclr| --- satisfy BCs on scalar |isclr|; return a modified |y|
			\4 |do istepc = 1, seqsize| --- loop over individual solves of flow and scalar
				\5 |icode = stepseq(istepc)| --- get sequence code
				\5 |if| this is a flow solve
					\6 |SolFlow|\ra --- perform a flow solve
				\5 |else if| this is a scalar solve
					\6 |SolSclr| --- perform a scalar solve
				\5 |else| this is an update
					\6 |itrCorrect|\ra and |itrBC|\ra --- update flow if desired
					\6 |itrCorrectSclr| and |itrBCSclr| --- update scalar if desired
			\4 |stsGetStats| --- obtain time averaged statistics
			\4 find solution at end of time step and move it to old solution variables
			\4 increment |istep| and |lstep|
			\4 |Bflux| --- compute the consistent boundary flux if desired
		\3 deallocate variables and close files
	\2 deallocate variables and close files
\end{outline}

The following routines specific to the generalized-alpha method are used primarily in |itdrv|, but some are called (above) to prepare input data, such as |itrBC| and |itrPredict|.

\begin{outline}[deep]
\1 |itrPredict| --- predict solution variables at time $n+1$
	\2 |if (ipred .eq. 1)| --- we are using same-velocity prediction, as discussed in class
		\3 set $\oset{n+1}{\ul{Y}}^{(i)} = \oset{n}{\ul{Y}}$ with |y = yold|
		\3 set $\oset{n+1}{\ul{Y}}^{(i)}_{,t} = (1-1/\gamma) \oset{n}{\ul{Y}}_{,t}$ with |ac = acold * (gami-one)/gami|
	\2 other prediction methods (zero-acceleration, same-acceleration, and same-delta) are also supported with different values of |ipred|
\end{outline}

Boundary conditions are set with the |iBC| and |BC| arrays. The bits of |iBC|, in increasing order, indicate whether the following BCs are set: $\rho$, $T$, $p$, $u_1$, $u_2$, $u_3$, scalars 1--4, periodicity, scaled plane extraction (SPEBC), axisymmetry, and deformable wall (for cardiovascular cases). This means for each global node, |iBC| has at least 14 bits. Note that |ibits(i,a,l)| extracts bits |a+1| through |a+l| of the integer |i|, and returns the base-10 integer. This routine is used to help identify and process boundary condition flags held in |iBC|. For example, if |ibits(iBC,3,3) .eq. 1| then $u_1$ is the only velocity component specified essential BC.
\begin{outline}[deep]
\1 |itrBC| --- satisfy BCs on the primitive variables
	\2 impose limits on flow variables in |y|, using the |ylimit| data structure of dimension |(3, nflow)|, whose first index contains the limit flag, lower limit, and upper limit for each flow variable
	\2 velocity
	\2 pressure
	\2 local periodic
	\2 global periodic
\end{outline}

In the event of an update, |itrCorrect| is called (followed by |itrBC|) to update the solution at time $n+1$, such that it is consistent with the most recent solve.
\begin{outline}[deep]
\1 |itrCorrect|
	\2 set $|fct1| = \gamma \Delta t$
	\2 set $|fct2| = \gamma \alpha_f \Delta t$
	\2 update velocity: $\oset{n+1}{\ul{Y}}^{(i)}_\text{velocity}| += fct1 * solinc(:,1:3)|$, where $|solinc(:,1:3)| = \oset{n+1}{\ul{Y}}^{(i)}_{\text{velocity},t}$
	\2 update pressure: $\oset{n+1}{\ul{Y}}^{(i)}_\text{pressure}| += fct2 * solinc(:,4)|$, where $|solinc(:,4)| = \oset{n+1}{\ul{Y}}^{(i)}_{\text{pressure},t}$
	\2 update acceleration: $\oset{n+1}{\ul{Y}}^{(i)}_{\text{velocity},t}| += solinc(:,1:3)|$
\end{outline}

Once boundary conditions have been satisfied at the beginning of an iteration, |SolFlow| is called from within |itrdrv| to perform a flow solve. The general form of the system we seek a solution to is
\begin{equation}
\begin{bmatrix}
\uul{K}    & \uul{G} \\
-\uul{G}^T & \uul{C}
\end{bmatrix}
\begin{bmatrix}
\Delta \ul{u}_{j,t} \\
\Delta \ul{p}_{,t}
\end{bmatrix}
=
\begin{bmatrix}
\oset{\text{mom}}{\ul{R}} \\
\oset{\text{cont}}{\ul{R}}
\end{bmatrix}
\end{equation}
Because we are looking at the incompressible code, the temperature equation is not included in the flow solve matrix system, and is instead solved separately as a scalar. Further note that in code, $\uul{K} = |xKebe|$, and $\uul{G}$ on top of $\uul{C}$ is |xGoC|.
\begin{outline}[deep]
\1 |SolFlow| --- perform a flow solve; output |res| preconditioned residual, 
	\2 |itrYAlpha| --- compute $\oset{n+\alpha_f}{\ul{Y}}^{(i)}$ and $\oset{n+\alpha_m}{\ul{Y}}^{(i)}_{,t}$, store respectively in |yAlpha| and |acAlpha|
	\2 |ElmGMR| --- compute tangent matrix, residual vector, and preconditioning matrix for GMRES
		\3 |if| using a global reconstruction approach
			\4 |do iblk = 1, nelblk| --- loop over element blocks
				\5 |if| this is the last time step and we need to compute vorticity, call |AsIqGradV|
				\5 |AsIq|\ra --- compute and assemble the diffusive flux residual vector |qres| and the lumped mass matrix |rmass|
			\4 |qpbc| --- satisfy periodic BCs on |rmass| and |qres|
		\3 initialize |res = 0|, which is the full system residual $\ul{G}_b$
		\3 |do iblk = 1, nelblk| --- loop over element blocks
			\4 |AsIGMR|\ra --- compute and assemble residual and tangent matrix
			\4 |bc3lhs| --- satisfy boundary conditions on the tangent matrix
				\5 |do| loop over elements |iel| and local shape functions |inod|
					\6 
			\4 |fillsparseI| --- fill the sparse tangent matrix data structures, 
		\3 |lmassadd| --- add lumped mass matrix contributions if we are lumping
		\3 compute time averaged statistics
		\3 |do iblk = 1, nelblb| --- loop over boundary element blocks
			\4 |AsBMFG| ---
			\4 |bc3lhs| --- 
			\4 |fillsparseI| ---
		\3 |rotabc| --- rotate the residual vector before cross-processor communication for efficiency
		\3 |commu| --- communicate with other processors
		\3 |bc3Res| --- satisfy boundary conditions on the residual vector
	\2 |usrNew| --- set up GMRES solver
	\2 |myfLesSolve| --- 
\end{outline}

The diffusive flux residual vector |qres| and the lumped mass matrix |rmass| are compred and assembed within |AsIq|:
\begin{outline}[deep]
\1 |AsIq|
	\2 gather $|y| \rightarrow |yl|$ and $|x| \rightarrow |xl|$ via |localy| and |localx|
	\2 initialize |ql = 0| and |rmassl = 0|
	\2 |e3q| --- compute the element-wise residuals |ql| and |rmassl|
		\3 |do intp = 1, ngauss| --- loop over Gauss points
			\4 |getshp| --- get shape functions and derivatives at Gauss points
			\4 |e3qvar| --- compute integration variables necessary for formation of |ql|; this routine is straight-forward, and returns |dxdxi|, |dxidx|, |WdetJ|, |shg|, and gradients of |y| in the usual manner
			\4 |getdiff| --- compute the viscosity at this point
			\4 compute diffusive fluxes, stored in |qdi|
			\4 add local node contributions to |ql|
			\4 compute local contribution to the lumped mass matrix |rmassl|
			\4 |if isurf .eq. 1| --- if surface tension is being computed, compute and fill the extra three indices of |ql|
		\3 normalize the mass matrix if desired (if |idiff == 3|)
	\2 scatter $|ql| \rightarrow |qres|$ and $|rmassl| \rightarrow |rmass|$
\end{outline}

Going through lectures 26 and 27.

First in the compressible code.
Data structures are used in |solgmr| -> |elmgmrs| (sparse). Section on diffusive flux reconstruction, set up some arrays for interior elements. call |asigmr|, took care of volume integrals. now come to boundary elements, which is where integral over gamma takes place. block boundary elements as a separate list of elements with separate connectivity. as |asbmfg| is called, |mienb| holds boundary elements. computing normal gradients requires nodes off of the boundary. solution goes into |asbmfg| (no time derivatives are input, unlike |asigmr|), out comes a modified solution. in |asibmfg|: working with a block of elements; solution and coordinates are localized, local residual is zeroed, call |e3b|, assemble local residual. in |e3b|: loop over quadrature points (|ngaussb|), |getshpb| to get boundary shape functions, |e3bvar| called with surface normals, need |Fv{2,3,4}| to evaluate the floating flux, let |e3bvar| compute |Fv| values and fluxes, then test if we should use computed value or value from prescribed boundary condition. in |e3bvar|: interpolate nodal values to quadrature points, call |getthm| to compute thermodynamic state, compute element metrics for mapping physical space to get |wdetj|, compute |rou|,|p| and |tau*n|,|heat| (normal flux, pressure, traction vector, heat flux) that is, |rou| takes $h^m(\xi_l)$, |p| takes $h^p(\xi_l)$, |tau*n| takes $h^v_*(\xi_l)$, etc. what's passed out is these things and the raw variables, their gradients, and the derived thermodynamic state. Back to |e3b|, do convective pressure, n-s, heat terms. after return from |e3bvar|, if no natural bc flag is set, we overwrite |rou|,|p| with floating values. compute euler stuff; then compute viscous stuff. get floating flux |tau*n|, overwrite where bits are not set. be careful what's passed out and in. also compute aerodynamic forces and heat flux in |e3b|, since we're doing surface integrals anyway.

incompressible is different, slightly. don't interpolate temperature at the outset; compute normal via cross-product; compute deformation gradient, local and global variable gradients; |unm| has the floating value of $\ul{u} \cdot \ul{n}$. eventually compute |tau*n|, which has the total stress floating value. skip over a bunch of deforming-wall stuff. iBCB did not come in to e3bvar; only floating flux stuff is computed in |e3bvar| for incompressible. all nodal interpolation is now done in |e3b|:

for Dirichlet bcs, |iBC| was a bitmap to boundary conditions |BC|

for natural bcs, |ibcb|(1:nel$_\text{in block (npro)}$,...) is a bitmap to boundary conditions |BCB|(:,...), where ... takes normal flux, pressure, traction vector, and heat flux take values 1--4.

going through more code... (2016-03-30)

this stuff is used in |irdrv| when it calls |solgmrs|, calls |elmgmrs| to populate lshk with current iteration's tangent values (same for |res|). allows us to start |gmres|; factorize matrix; precondition rhs with |i3lu|; |spsi3pre| sparse matrix preconditioning of |lhsk|; copy preconditioned residual into |uBrg|, which is a collection or Krylov vectors; calculate it's norm, make orthonormal; outer gmres loop |do 2000| can be skipped, which is the gmres restart; actual start of GMRES discussed in class is |uBrg| statement just before |do 1000|; |sumgat| does off-processor (communication).


\begin{center}
\begin{tabular}{@{}lll@{}}
\toprule
Symbol & Dimension & Description \\
\midrule
|nshg|   &  & \# global shape functions (|nshg| = |nnp| if piecewise linear) \\
|nnp|    &  & \# global nodal points \\
|npro|   &  & \# elements in a block of same-topology elements, indexed by $e$ \\
|nshl|   &  & \# nodes per element, indexed by $a$ \\
|ndof|   &  & \# degrees of freedom, including scalars for turbulence models \\
|nflow|  &  & \# flow variables (4 incompressible, 5 compressible) \\
|ntseq|  &  & \# time sequences, which seems seldom used and defaults to 1 \\
|nstep|  &  & \# time steps requested per sequence \\
|nelblk| &  & \# element blocks \\
|ipord|  &  & order of basis functions \\
|lstep|  &  & current time step \\
|lstep0| &  & first time step solved by current run, initialized to |lstep+1| \\
|istep|  &  & step number relative to start of run \\
|iter|   &  & iteration number \\
|niter|  & |(MAXTS)|    & \# multi-corrector iterations per time step \\
|loctim| & |(MAXTS)|    & local time stepping flag (?) \\
|deltol| & |(MAXTS, 2)| & velocity and pressure delta ratios \\
|impl|   & |(MAXTS)|    & heat, flow, and scalar solver flags (1's, 10's and 100's places) \\
|iturb|  &  & indicates which turbulence model to use \\
|ifunc|  &  & function evaluation counter, |niter*(lstep-lstep0)+iter| \\
|ifuncs| & |(6)|						& function evaluation counter (?) \\
|y|      & |(nshg, ndof)|            & $\oset{n+\alpha_f}{\ul{Y}}_{A}^{(i)}$ (meaning changes throughout) \\
|ac|     & |(nshg, ndof)|            & $\oset{n+\alpha_m}{\ul{Y}}_{A,t}^{(i)}$ (meaning changes throughout) \\
|yold|   & |(nshg, ndof)|            & $\oset{n}{\ul{Y}}_{A}^{(i)}$ (meaning changes throughout) \\
|acold|  & |(nshg, ndof)|            & $\oset{n}{\ul{Y}}_{A,t}^{(i)}$ (meaning changes throughout) \\
|x|      & |(nshg, nsd)|             & node coordinates \\
|iBC|    & |(nshg)|                  & BC codes \\
|BC|     & |(nshg, ndofBC)|          & BC constraint parameters \\
|iper|   & |(nshg)|				    & periodicity table \\
|mien|   & |(nelblk)|			    & pointer to IEN array (interior): has dimension |(nshg, 15*nnz)| \\
|mienb|  & |(nelblk)|			    & pointer to IEN array (boundary): has dimension |(nshg, 15*nnz)| \\
|shp|    & |(nshape, ngauss)|        & physical shape functions at Gauss points (interior) \\
|shb|    & |(nshapeb, ngaussb)|      & physical shape functions at Gauss points (boundary) \\
|shgl|   & |(nsd, nshape, ngauss)|   & parent shape function gradients at Gauss points (interior) \\
|shglb|  & |(nsd, nshapeb, nguassb)| & parent shape function gradients at Gauss points (boundary) \\
\bottomrule
\end{tabular}
\label{tbl:symbols}
\end{center}

\section{General Notes}
\begin{outline}[deep]
\1 In PHASTA, a block contains elements of the same topology.
\end{outline}

\section{Life's Persistent PHASTA Questions}
\begin{outline}[deep]
	\1 Is |qold|, allocated in |readnblk.f| ever deallocated? Can't find it.
	\1 Why do most of the time step parameters have dimension |MAXTS|?
		\2 It also seems that some parameters are indexed by |itseq|, but don't change from step to step.
	\1 When is it the case that $|ndof| \ne |nflow|$? For example during its limit-imposing stage, |itrbc| loops over |nflow| when indexing |y|'s dimension of size |ndof|.
	\1 Often the value of |datmat(1,2,1)| is assigned to a variable like |rmu|; where it it calculated? Kinematic viscosity? See |getdiff|.
	\1 In |genBC1|, |BC(:,1)| gets assigned both density and pressure, so what goes in |BC(:,6)|???
\end{outline}

%%
%% DOCUMENT END
%%
\label{lastpage}
\end{document}






